\subsection{Pre-built Channels} By default, Tor attempts to pre-build circuits to reduce latency once a user wishes to create a data stream.
Much like circuits, moneTor payment channels are high in initial latency because of the multiple in-out messages in the protocol.
To solve this problem, we exploit the same circuit build strategy by preemptively setting up and establishing payment channels on clean pre-built circuits.
This approach dramatically reduces the time-to-first-payment.
Unfortunately, the excessive establishment of preemptive channels introduces network overhead.
Our implementation features a basic prediction strategy to balance this trade-off by using historical usage date to anticipate the required number of channels.
The approach is similar to the way in which Tor anticipates the need for a fresh circuit.
In Section~\ref{sec:experimentations}, we analyze moneTor's preemptive channels approach and show that the payment confirmation time matches the round-trip-time of the client-relay connection, as expected.

\subsection{Prioritized Traffic}
\label{subsub:prioritized}

Traffic scheduling is perhaps the most intuitive mechanism with which to implement prioritization.
However, our preliminary experiments found that local scheduling decisions on each relay for priority do not work well with the current Tor network, which precludes the use of out-of-the-box scheduling approaches based on DiffServ~\cite{dovrolis1999case} and EWMA~\cite{tang2010improved}.
Intuitively, this behavior is a direct result of the evolution of the Tor network capacity in recent years.
The growth in bandwidth across guard and middle relays produces more congestion between the exit relay and the final destination.
We simulated Tor's topology to analyzing scheduling and found that relays were able to instantaneously flush their queues at each ``write'' event, rendering any attempt at local scheduling to be ineffective.
These results, detailed in Appendix~\ref{sec:scheduling}, may suggest a need for a separate comprehensive study of network prioritization mechanisms.

Consequently, we turn to the alternative strategy of prioritizing traffic through Tor's internal control-flow window sizes.
Unlike scheduling-based approaches, window-based approaches tend to be more accurate under lower internal congestion conditions~\cite{archive-2009-mail, kiraly2008solving}.
Indeed, since local decisions inside the scheduler at a particular relay may fail to achieve priority, we need to design priority as a global function of the circuit.
Recall that edge nodes regulate the traffic flux in either direction using a set of flow control windows.
Roughly speaking, these windows determine the space allotted to each circuit on a relay's scheduling queue, which in turn positively correlates with effective bandwidth.
We implement our prioritization scheme by statically readjusting the window maximum sizes once according to the following formula for both \emph{Circ window} and \emph{Stream window}.
\begin{equation} window' = window(1+ \alpha(premium / pr\% - 1)) \label{eq:flow} \end{equation} Here, a circuit is marked as prioritized by the bit $premium \in \{0, 1\}$.
The tunable priority benefit $\alpha \in [0, 1]$ defines the proportion of the non-premium capacity that we wish to transfer to premium clients.
By accounting for $pr\% \in [0,1]$, the fraction of premium to nonpremium clients, we can keep the total flow capacity constant.
It follows that the memory consumption at relays induced by processing cells should stay constant too.

Even if most relays can flush all queues at each ``write'' event, some relays may still suffer from congestion within the Tor network.
In this case, modifying Tor's overlay flow control will not achieve priority since the cells are stuck within the congested relay's queues.
To overcome this issue, we modify EWMA with a linear scaling factor that favors paid circuits.

\begin{equation}
  A_{t + \Delta t} = A_t \times 0.5^{\Delta t/H}
\end{equation}
\begin{equation}
  A'_{t + \Delta t} = A_{t + \Delta t} / \beta + C_{t, t + \Delta t}
\end{equation}

Defined in Tang and Goldberg's original paper~\cite{tang2010improved}, $A$ is a variable score used to sort circuits such that the circuit with the lowest $A$ is always next on the scheduling queue.
$C$ is the number of cells relayed within $\Delta t$, the time that has passed since the previous observation, and $H$ is a global parameter representing the half-life decay interval.
Our added term, $\beta \in [1, \inf)$, is a tunable parameter such that $\mathit{Bandwidth}_{\mathit{premium}} = \mathit{Bandwidth}_{\mathit{nonpremium}} \times \beta$ for any given circuit under ideal conditions.

Finally, note that our design focuses on the conditions of the current Tor network, where the vast majority of traffic exits the network and congestion occurs primarily at exits.
Although it is not inherently incompatible with our scheme, we leave the prioritization of internal onion services, which do not pass through exits, for future work.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
