\subsection{background: scheduling}

Tor handles multiple queues of cells for each circuit and writes cells in the
outbound connection while favoring bursty over bulky traffic. The main idea is
to prioritize circuit handling interactive data streams, like chats or web
browsing. Tor uses an heuristic called EWMA~\cite{tang2010improved} (i.e.,
computes the exponentially weighted moving average for the number of cells sent
on each circuit) to decide which circuit to prioritize. Recently, the efficiency
of EWMA has been improved with the Kist~\cite{jansen2014never} scheduler used to
reduce the congestion on the kernel outbound queue and push back this delicate
problem on to the Tor layer.

In an ideal network, we might expect that traffic movement is an exclusive
function of the raw bandwidth capacity in each edge connection and the
scheduling algorithm implemented at each node.  The Tor network employs EWMA to
favor interactive web clients over continuous bulk clients. In moneTor, we
originally proposed to modify EWMA with a simple linear scaling factor that
would favor paid circuits.
\begin{equation}
  A_{t + \Delta t} = A_t \times 0.5^{\Delta t/H}
\end{equation}
\begin{equation}
  A'_{t + \Delta t} = A_{t + \Delta t} / \beta + C_{t, t + \Delta t}
\end{equation}
Defined in Tang and Goldeberg's original paper~\cite{tang2010improved}, $A$ is a variable score used to
sort circuits such that the circuit with the lowest $A$ is always next on the
scheduling queue. $C$ is the number of cells relayed within $\Delta t$, the time
since the previous observation, and $H$ is a global representing the half-life
decay interval in the score. Our added term, $\beta \in [1, \inf)$, is a tunable
parameter such that $Bandwidth_{premium} = Bandwidth_{nonpremium} \times \beta$
for any given circuit under ideal conditions.

\subsection{Obstacles}

Implementation into the concrete Tor infrastructure has proven to be a
considerably more complex problem. Upon failing to achieve meaningful
differentiation with low values of $\beta$, we adopted a more blunt policy which
\emph{always} services premium circuits first and implemented it in a
zero-overhead version of moneTor.\footnote{This ideal version of moneTor strips
  away all payment operations and instead passes a single signal through the
  network to distinguish premium circuits.} The results are displayed in
Figure~\ref{fig:scheduling_priority}. Although we observed some moderate
differentiation, the difference falls well short of the benefit needed to
incentivize paid users as well as our expectations for such an inequitable
scheduling policy. This result holds even under very heavy levels of induced
congestion.

This is quite a severe issue since all previous works are using strategies that make local scheduling decisions on each relay only to serve premium bandwidth. We observe that offering bandwidth priority based on local decisions seems not to work well anymore.

\begin{figure} \centering
  \includegraphics[trim={0 3cm 0 3cm}, clip, width=0.32\textwidth]{images/scheduling_priority.pdf}
  \caption[Prioritized Scheduling]{Prioritized Scheduling --- CDF download
    times for superimposed web and bulk clients where premium status is enforced
    only via scheduling.}
  \label{fig:scheduling_priority}
\end{figure}

\subsection{Investigation and discussion}

Our negative results can be explained if scheduling is not the most decisive
determining factor in performance. To verify this hypothesis, we studied the
incoming queue from which the scheduler is able to select new active
circuits. Figure~\ref{fig:scheduling_far} illustrates the temporal load in the
queue at a single exit relay over a one-minute time span. The height of the
curve represents the total number of cells waiting to be serviced at each
continuous point in time while the colors group quantities of cells that belong
to the same circuit. Figure~\ref{fig:scheduling_close} displays a subset of the
same information within a smaller time interval.\footnote{While the graph has
  the visual appearance of a bar graph, this is just a function of the striking
  data pattern. In actuality, the plot displays a stacked area graph.} In the
aforementioned figures, notice that the queue is only populated for a period of
10 $ms$ before it is completely flushed, implying the queue spends the vast
majority of its time empty. This 10 $ms$ window is a product of Tor's internal
event handling framework and is consistent with data from Jansen et
al~\cite{jansen2017tor}. We found in an analysis of the line-by-line
observations of the queue activity that while cells are flushed in the correct
order, they appear in the queue at roughly equal proportions. In effect,
bandwidth in our simulation is not constrained by the ordering policy of the
scheduler but rather by the rate at which they arrive from the network. As a consequence, local decisions at a particular relay for scheduling falls short to offer the expected priority.


\begin{figure} \centering
  \includegraphics[width=0.49\textwidth]{images/scheduling_far.png}
  \caption[Queue Temporal Profile (60 seconds)]{Queue Temporal Profile
      (60 seconds) --- Size of the scheduling buffer over time at a single exit
    relay in terms of number of cells. Colors group cells belonging to the same circuit.}
  \label{fig:scheduling_far}
\end{figure}

\begin{figure} \centering
  \includegraphics[width=0.49\textwidth]{images/scheduling_close.png}
  \caption[Queue Temporal Profile (2 seconds)]{Queue Temporal Profile
      (2 seconds) --- Size of the scheduling buffer over time at a single exit
    relay in terms of number of cells. Colors group cells belonging to the same
    circuit.}
  \label{fig:scheduling_close}
\end{figure}

Now, we may investigate why prioritisation based on making decisions inside the 
relay's scheduler worked fine for previous works such as BRAIDS and LIRA while we 
follow the same methodology to evaluate moneTor. So, what could be wrong? First, 
it may be the case
that other network control mechanisms within the Tor codebase constrain the flow
of cells, rendering the mostly idle scheduler to be ineffective. This may be
caused by any combination of factors including point-to-point flow control,
connection throttling, or some less documented threshold embedded in the
code. Yet, we believe that some differences in the code could not explain our 
results for the following reason: our positive results covered in Section~
\ref{sec:priority_exp} showing
increasing performance (resp. decreasing) when we increase (resp. decrease) the 
circuit windows are counter-intuitive compared to previous works exploring the 
effect of changing the window sizes~\cite{archive-2009-mail, kiraly2008solving, 
dingledine2009performance}, and Tor's code covering those aspects did not change 
meaningfully for many years. This is an interesting piece of information, and we 
expect these results to be linked to our actual 
problem of not achieving to prioritize flows based on relays' scheduler decision.

To explain those oddities, we found and verified the following reason: the 
constraining network bottleneck does not lie within the
Tor network itself but at the exit relay interface with external servers on the
web. In this scenario, cell queuing within Tor is not nearly as important as the
TCP/IP packet handling at each exit relay. Actually, both approaches to prioritize 
flows are complementary: when the congestion is inside the Tor network, applying 
local scheduling policies makes an efficient priority mechanism. However, priority 
based on the flow-control (that is, a function of the global circuit) would not be 
efficient, because all cells would spend the majority of the time waiting in 
relays' FIFO queues anyway. In the opposite, if the congestion is outside the Tor 
network (between the exit relays and the destination), then local scheduling 
policies would fall short to make any prioritization, but priority based on the 
flow-control would achieve to prioritize flows, as demonstrated in Section~\ref{subsec:experiments}. 

One mystery remains: why are our scheduling results so different from BRAIDS and LIRA? BRAIDS run experiments with Tor version 0.2.0.35~\cite{braids-repository}. This Tor 
version's commit date is before a major change in the path selection mechanism that reduced Tor's 
internal congestion problem and greatly improved performance. This major change was 
introduced as the well-known bandwidth-weights in Mike Perry's commit 
0ff86042ac16 dated from September 2010. The bandwidth-weights are a set of weights 
specified in the directory specifications, section 3.8.4~\cite{dirspec}, that aim at 
balancing the overall network usage for each relay position. Those weights are 
critical for the network performance, and also for anonymity~\cite{waterfilling-
pets2017, wf_proposal}. Importantly, the benefit of Mike Perry's bandwidh-weights 
are proportional to the inequalities between the overall bandwidth in circuit 
positions. These inequalities are growing fast for years, as we can observe on 
Figure~\ref{fig:bw_inequalities}. In consequences, compared to BRAIDS's experiments, 
we are no more in a situation where we have a lot of internal congestion, and we 
cannot achieve the same priority improvement using a local scheduler at each relay.

\begin{figure}
	\includegraphics[scale=0.415]{images/bandwidth-flags-2011-01-01-2019-02-25.pdf}
	\caption{Bandwidth aggregated by relay flags}
	\label{fig:bw_inequalities}
\end{figure}

Then, we could argue that an ideal priority mechanism that covers various aspect of circuit congestions may be composed of local scheduling decisions and circuit-wide policies. We leave the design of a new priority-based scheme that works under various congestion situation as a further work.

%To confirm it, we run highly congested simulations with many more Tor 
%clients than what the scaled-down Tor network could reasonably handle, and observed the same results: we were not able to achieve meaningful flow priority with local scheduling decisions, but only by tweaking the flow-control mechanism.

We must emphasize that our results are in no way indicative or predictive of the
state of affairs on the live Tor network. The aforementioned experiments were
performed on a considerably smaller scale with simplistic models for network
topology and user behavior. What can be said is that networking as a whole is an
immensely complex and unpredictable domain and that the attainment of a
simulation environment conducive to effective scheduling is, at the very least,
nontrivial.
